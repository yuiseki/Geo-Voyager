# **Geo-Voyager 要件定義書**

## **1. プロジェクト概要**

Geo-Voyager は、生成 AI によって反復的に仮説を生成・評価・検証することで現実世界の地理空間洞察（Geospatial Insights）を最大化する、自律エージェントシステムです。Geo-Voyager は行政区画（Administrative）を基本単位とし、仮説-洞察ライブラリとスキルライブラリを用いて自己学習を進めます。Geo-Voyager は失敗や未検証の仮説から試行錯誤と改善を繰り返し、時間とともに成長します。

---

## **2. エージェントの目標**

- **目標**:
  - 仮説の生成・評価・検証を通じて有用な洞察を最大限に得る。
- **評価指標**:
  - 洞察の数と質を測定。
  - 仮説スコア（陳腐さスコア、荒唐無稽さスコア）を用いて仮説の質を評価。

---

## **3. 必要最小限の要件**

### **3.1 機能要件**

#### **3.1.1 仮説生成**

1. **概要**:

- エージェントは行政区画（Administrative）ごとに、新しい仮説を生成する。

2. **詳細要件**:

- 行政区画は OpenStreetMap の Administrative に基づく。
- 仮説は自然言語で記述される。
- 仮説-洞察ライブラリから仮説スコア（仮説の陳腐さスコア、仮説の荒唐無稽さスコア）を計算し、適切な仮説ができるまで、データ収集や検証ステップには移らない。
- 生成された仮説は、仮説-洞察ライブラリに「未検証」として記録する。

---

#### **3.1.2 データ収集**

1. **概要**:

- 仮説を検証するためにスキルライブラリを基に外部データソースから必要なデータを収集する。

2. **詳細要件**:

- OpenStreetMap の Overpass API を使用して地理空間情報を取得。
- 必要に応じて他のオープンデータ API（例: 世界銀行、UN OCHA HDX）からデータを取得する。
- 10 回試行錯誤してもデータが得られない場合、仮説-洞察ライブラリを、「検証不可能（データ取得失敗）」として更新する。

---

#### **3.1.3 仮説検証**

1. **概要**:

- 収集したデータとスキルライブラリを基にデータ分析コードを生成・実行して、仮説を検証する。

2. **詳細要件**:

- 仮説が支持された場合、仮説-洞察データベースを、検証済み（洞察）として更新する。
- 仮説が棄却された場合、仮説-洞察データベースを、検証済み（棄却）として更新し、逆仮説を生成する。
- 検証に失敗した場合は、仮説-洞察データベースを、「検証不可能（データ分析失敗）」として更新する。

---

#### **3.1.4 スキルライブラリ**

1. **概要**:

- 仮説検証に成功した API クエリやコードをスキルとして蓄積し、再利用可能にする。

2. **詳細要件**:

- スキルは以下の 2 種類に分類される：
  - **FetchSkill**: データ収集用のスキル。
  - **AnalyzeSkill**: データ分析用のスキル。
- 各スキルは、名前（name）、説明（description）、内容（code）を持つ。
- スキルライブラリは次回以降のデータ収集や仮説検証で活用可能とする。

---

#### **3.1.5 仮説-洞察ライブラリ**

1. **概要**:

- 仮説の生成・検証結果を記録し、仮説スコア計算の基盤とする。また、最終的に構築する洞察のライブラリとする。

2. **詳細要件**:

- 仮説は以下の状態で管理される：
  - PENDING
  - VERIFIED
  - REJECTED
  - UNVERIFIABLE_FETCH（データ収集失敗）
  - UNVERIFIABLE_ANALYZE（データ分析失敗）
- 検証の結果、支持された仮説のことを洞察と呼ぶ。
- 検証の結果、棄却された仮説から逆仮説を生成できる。

---

#### **3.1.6 反復プロンプトメカニズム**

1. **概要**:

- データ取得やデータ分析の失敗時に、反復プロンプトメカニズムを用いて改善する。

2. **詳細要件**:

- エラーの原因を自律的に解析し、クエリやコードの修正を試みる。
- 成功すればスキルライブラリに保存する。

---

## **4. 仮説スコア計算の基準**

仮説スコアは、以下の要素で評価される：

1. **陳腐さスコア \( C(x) \)**:

仮説 \( x \) と既存の仮説（VERIFIED または REJECTED）の類似性を測定。

\[
C(x) = \max\_{h \in \text{ExistingHypotheses}} \text{Similarity}(x, h)
\]

2. **荒唐無稽さスコア \( K(x) \)**:

仮説 \( x \) と検証不可能だった仮説（UNVERIFIABLE_FETCH または UNVERIFIABLE_ANALYZE）の類似性を測定。

\[
K(x) = \max\_{h \in \text{UnverifiableHypotheses}} \text{Similarity}(x, h)
\]

3. **総合スコア \( S(x) \)**:

陳腐さスコアと荒唐無稽さスコアを組み合わせた総合スコアを計算。

\[
S(x) = (1 - C(x)) \cdot (1 - K(x))
\]

---

## **5. システムフロー**

1. **初期化**:

- 行政区画データを取得し、未探索エリアやカテゴリを特定。

2. **仮説生成**:

- 仮説ライブラリを参照して新しい仮説を生成。
- 仮説スコアを計算し、最適な仮説を選択。

3. **データ収集**:

- 仮説を検証するために必要なデータを収集。
- 収集に失敗した場合、反復プロンプトメカニズムを呼び出し、修正。

4. **仮説検証**:

- データを基に仮説を検証し、洞察または逆仮説を生成。

5. **スキル改善**:

- 成功したクエリやデータ分析コードをスキルライブラリに保存する。
- 失敗したスキルは反復プロンプトメカニズムで改善を試行錯誤する。

6. **洞察記録**:

- 得られた洞察を記録し、次の仮説生成に活用。

---

## **6. 必要なデータソース**

1. OpenStreetMap Overpass API

- 地理空間データの取得。

2. 世界銀行

- 人口や社会経済データ。

3. UN OCHA HDX

- 災害データなど。

4. 他のオープンデータ API を追加可能
